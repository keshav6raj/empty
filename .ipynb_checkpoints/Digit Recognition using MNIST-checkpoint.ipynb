{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dataset= tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train) , (x_test,y_test) = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) #60000 images of size 28*28 pixels\n",
    "print(x_test.shape) #10000 images of size 28*28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4D array is required to use keras API and we have 3D, so we will reshape the arrays\n",
    "x_train= x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test= x_test.reshape(x_test.shape[0],28,28,1)\n",
    "in_shape = (28,28,1)\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train.dtype) #its uint8 but we should convert it to float32(safeside)\n",
    "x_train= x_train.astype('float32')\n",
    "x_test= x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20c702f7ee0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample_img = x_train[100, :, :, :]\n",
    "sample_img = sample_img.reshape(28,28) #matplotlib.pyplot.imshow() needs a 2D array, \n",
    "                                        # or a 3D array with the third dimension being of shape 3 or 4 !\n",
    "# sample_img.shape\n",
    "plt.imshow(sample_img, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization: dividing by 255 i.e. the maximum RGB code minus the minimum RGB code.\n",
    "x_train/=255\n",
    "x_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 804,554\n",
      "Trainable params: 804,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL BUILDING\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(filters= 32,kernel_size= (3,3), padding='same', activation = 'relu', input_shape=in_shape))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units= 128, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=10, activation= 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using EarlyStopping, end training when val_accuracy is not improved for 10 consecutive times\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy',mode='max',\n",
    "                                    patience=10,restore_best_weights=True)\n",
    "\n",
    "# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 5 consecutive times\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',mode='max',factor=0.5,patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "300/300 [==============================] - 18s 61ms/step - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 2/15\n",
      "300/300 [==============================] - 18s 62ms/step - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 3/15\n",
      "300/300 [==============================] - 20s 66ms/step - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 4/15\n",
      "300/300 [==============================] - 20s 68ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 5/15\n",
      "300/300 [==============================] - 20s 65ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 6/15\n",
      "300/300 [==============================] - 19s 62ms/step - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 7/15\n",
      "300/300 [==============================] - 20s 65ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 8/15\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.0033 - accuracy: 0.99910s - loss: 0.0033 - accura\n",
      "Epoch 9/15\n",
      "300/300 [==============================] - 20s 66ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 10/15\n",
      "300/300 [==============================] - 20s 67ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 11/15\n",
      "300/300 [==============================] - 19s 64ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 12/15\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 13/15\n",
      "300/300 [==============================] - 20s 66ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 14/15\n",
      "300/300 [==============================] - 19s 63ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 15/15\n",
      "300/300 [==============================] - 19s 64ms/step - loss: 0.0024 - accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "#fitting model\n",
    "history= model.fit(x_train,y_train,epochs=15,batch_size= 200 ,callbacks=[early_stopping,lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_exact\\t\\t\"  \"y_predict\")\n",
    "# let's predict some values\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    \n",
    "    plt.imshow(x_test[i].reshape(28, 28),cmap='Greys')\n",
    "    # x_test[i].shape it's again 3D, so for predicting we need to pass it as 4D\n",
    "    pred = model.predict(x_test[i].reshape(1,28,28,1))\n",
    "    print(y_test[i],'\\t\\t', pred.argmax())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
